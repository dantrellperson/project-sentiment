{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9fd6793-03b5-4ecc-9e95-d75cc23188f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# exploring different areas of text analytics.\n",
    "_Looking to generate ideas for improving SICK_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc210a-8966-4c38-9e5a-6b4753a8b97f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## methods I'm exploring \n",
    "\n",
    "### * Bag of Words method\n",
    "> - taking each word from a sentence to get some kind of measure by which we can find out if the word exists in another sentence or not and also its importance\n",
    "> - each sentence in the google reviews will be treated as a bag of words, in other words each sentence is a **document** and all the documents make up a **corpus**\n",
    "\n",
    "#### goals\n",
    "1. create a dictionary of all the unique words in the corpus (exclusding words like \"the\", \"an\", \"is\" etc)\n",
    "1. convert all documents into vectors which will represent the presence of words from our dictionary in the documents.\n",
    "* *We're going to do this with the Tf-idf vectorizer in sklearn*\n",
    "\n",
    "#### steps\n",
    "1. Count the number of times each word appears in each document(hotel review)\n",
    "    1. create feature vector and find out of how many zeroes are in my feature vector.\n",
    "    1. calculate the non-zero value density in the vector\n",
    "    1. remove stopwords and non-english characters\n",
    "    1. test stemming or lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbed896-0d21-4b36-a09e-fb619a37f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plit\n",
    "import seaborn as sns\n",
    "import random\n",
    "import regex as re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd96c1-7f6b-40ab-8209-2655a06f6bb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985d9f88-8ff8-41c2-aba6-3021049730e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initData = pd.read_csv('resources/McDonald_s_Reviews.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab33e1-d9ca-400d-86b1-c7800906971b",
   "metadata": {},
   "source": [
    "## let's do some quick initial cleaning and exploring into the google data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f1f0f4-af3a-4ec2-adc1-343743a17291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33396 entries, 0 to 33395\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   reviewer_id    33396 non-null  int64  \n",
      " 1   store_name     33396 non-null  object \n",
      " 2   category       33396 non-null  object \n",
      " 3   store_address  33396 non-null  object \n",
      " 4   latitude       32736 non-null  float64\n",
      " 5   longitude      32736 non-null  float64\n",
      " 6   rating_count   33396 non-null  object \n",
      " 7   review_time    33396 non-null  object \n",
      " 8   review         33396 non-null  object \n",
      " 9   rating         33396 non-null  object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "initData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd48c96-b9b3-49c2-be7f-0f7916ea095f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review\n",
       "Excellent                                2148\n",
       "Good                                     1264\n",
       "Neutral                                   942\n",
       "Poor                                      315\n",
       "Terrible                                  292\n",
       "                                         ... \n",
       "then the worst burger here in the US        1\n",
       "it's a McDonalds                            1\n",
       "There are employees who speak Spanish       1\n",
       "What you order                              1\n",
       "they took good care of me                   1\n",
       "Name: count, Length: 22285, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get a quick overview of how many reviews share the same text with value_counts function\n",
    "initData['review'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e628ae6-4a6a-4ccd-a283-53f59956cf85",
   "metadata": {},
   "source": [
    "## * Bag of Words method start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f93d0b3-a6d3-4b6f-b891-d3c269631d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the countvectorizer \n",
    "count_vector = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bab9414-f4b6-482e-950d-a3349b1e1f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dictionary of words from the corpus\n",
    "features = count_vector.fit(initData['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac6df58-f2e9-48ec-9e5f-88e0042f3fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000000', ..., 'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý',\n",
       "       'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý',\n",
       "       'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to check out some words that got extracted from the corpus\n",
    "feature_names = features.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "389abf04-70fc-4f9f-bc65-d3c6170efed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000000', ..., 'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý',\n",
       "       'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý',\n",
       "       'ýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýýý'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f870c604-9ab0-4118-8505-53c6fb2e1e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features extracted are: 14378\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of features extracted are: {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b6858-fb35-49a5-921e-bbb30058f88c",
   "metadata": {},
   "source": [
    "**ok bet, we have 14378 unique features identified**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3d837a-012d-43a2-845e-4cead0603ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tge',\n",
       " 'aak',\n",
       " 'warden',\n",
       " 'cameras',\n",
       " 'forgiveness',\n",
       " 'specialist',\n",
       " 'ofen',\n",
       " 'dammmm',\n",
       " 'effert',\n",
       " '73rd']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a random sampler to show 10 feature names\n",
    "random.sample(sorted(feature_names),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c6f32e-4598-4f88-b23b-9326869825b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33396, 14378)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating feature vector\n",
    "feature_vector = count_vector.transform(initData['review'])\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5439d27-38d9-4445-9bf7-0c21c6d0badf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### the above shows us all 50,000 documents, are represented by 27,373 features(unique words)\n",
    "> corresponding features will carry the number of times that word appeard in the document. If the word is not present then the feature gets a 0 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef723ae5-099a-4527-92d7-6f75300944c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I need to find out of how many zeroes are in my feature vector\n",
    "feature_vector.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa052ee9-ca02-4588-aae4-75fa21c310d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011997079653556363"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the non-zero value density in the document\n",
    "feature_vector.getnnz()/(feature_vector.shape[0]*feature_vector.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb4c24-70ff-4120-aaf2-75c85af10049",
   "metadata": {},
   "source": [
    "wayyy too many zeroes in my feature vector **sadnesss -_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9375907d-c514-4dda-9fdd-b42bc4f8d847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sparse matrix\n",
    "feature_vector.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd60894-d44f-4fd2-a951-668ad192882f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### need to fix the dataset before moving forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f118073-595f-43db-bdb1-12d5b17d5a1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### * getting rid of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01be077c-0b59-4da4-9132-9cb8d4789096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create stopwords variable set to english\n",
    "all_stopwords = set(stopwords.words('english'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
